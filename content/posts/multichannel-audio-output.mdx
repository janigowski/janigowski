---
title: 'How to Play Sounds on Multichannel Mixer Using Tone.js and WebAudio'
description: 'A practical guide to routing audio through multiple channels in web browsers using Tone.js and WebAudio API'
date: '2024-01-01'
published: true
---

Ever tried playing different sounds through specific outputs in your web app? Like sending the kick drum to outputs `1-2` and vocals to `3-4`? If you've worked with professional audio interfaces like `Allen & Heath PX5`, you know this should be straightforward. But in web browsers? Not so much! 🎧

## The Challenge: Browser Audio is Stereo-Only by Default

Here's what we're dealing with: Modern DJ software like `Traktor`, `Serato`, or `Rekordbox` lets you route different decks to different outputs. For example, you might want to preview the next track in your headphones while the current track plays through the main speakers. In my setup, I'm using the `Allen & Heath PX5` mixer which has 5 stereo channels (that's 10 channels when routing audio):

- Channels `1-4` are standard fader channels for your decks
- Channel `A` is a special channel for connecting standalone devices like `Native Instruments Maschine`

But here's the catch: web browsers are designed with simple `stereo output` in mind - just your regular `left` and `right` channels. The browser's default audio routing isn't built for this kind of professional DJ setup. But don't worry - I've got a solution that works beautifully with professional audio interfaces! 🎛️

## The Magic Behind Channel Splitting and Merging

Think about your home audio system. When you're playing music from your phone, you might want to:
- Play it through your living room speakers
- Send it to your wireless kitchen speaker
- Or play it through both at the same time

That's exactly what we're building here, but for professional audio equipment. Instead of rooms, we have `channels`. Just like you can choose which speakers play your music at home, our system lets you choose which `channels` play your audio. 

The process is simple:
1. Take the audio source (like your music track)
2. Create copies of it (like your phone sending the same music to different speakers)
3. Send each copy to its destination (like different speakers in different rooms)

This way, you can play the same sound through multiple `channels`, or different sounds through different `channels` - just like having different songs playing in different rooms of your house! 🎚️

## The Solution: `Tone.js` + `WebAudio` Channel Routing

Let's make this happen! First, we need to set up our `AudioContext` with the right channel configuration:

```typescript
interface AudioContextConfig {
  channelCount: number;
}

const setupAudioContext = (config: AudioContextConfig): AudioContext => {
  const audioContext = new AudioContext();
  audioContext.destination.channelInterpretation = "discrete";
  audioContext.destination.channelCountMode = "explicit";
  audioContext.destination.channelCount = config.channelCount;

  // Initialize Tone.js with our context
  Tone.setContext(audioContext);
  
  return audioContext;
};

const audioContext = setupAudioContext({ channelCount: 10 });
```

Now for the interesting part - our channel routing system:

```typescript
interface AudioManagerConfig {
  audioContext: AudioContext;
}

class AudioManager {
  private readonly audioContext: AudioContext;
  private channelSplitters: ChannelSplitterNode[] = [];
  private sounds: Map<string, Tone.Player> = new Map();

  constructor(config: AudioManagerConfig) {
    this.audioContext = config.audioContext;
  }

  async createChannelMergers(): Promise<void> {
    // Get the number of outputs available on the sound card
    const numOutputs = this.audioContext.destination.maxChannelCount;
    this.audioContext.destination.channelCount = numOutputs;

    // Create ChannelSplitterNodes for each stereo pair
    for (let i = 0; i < numOutputs / 2; i++) {
      const splitter = this.audioContext.createChannelSplitter(2);
      this.channelSplitters.push(splitter);
    }

    // Create a merger to combine all channels
    const channelMerger = this.audioContext.createChannelMerger(numOutputs);
    channelMerger.connect(this.audioContext.destination);

    // Connect splitters to specific channel pairs in the merger
    for (let i = 0; i < numOutputs / 2; i++) {
      const [firstChannel, secondChannel] = [i * 2, (i * 2) + 1];
      this.channelSplitters[i].connect(channelMerger, 0, firstChannel);
      this.channelSplitters[i].connect(channelMerger, 1, secondChannel);
    }
  }
}
```

## Important Note About `Transport`

Let me share a tricky issue I encountered with `Tone.js`. Everything looked perfect in my code - `Transport` started, timer was increasing, audio was connected to the channels. But... silence. Complete silence. No errors, nothing in the console, just silence. 🤔

After hours of debugging and diving into the source code, I discovered something interesting. While both `Tone.Transport` and `Tone.getTransport()` should technically work the same way (according to the docs), they don't always behave identically in practice. I suspect there might be two `Transport` instances running in some cases, creating a "false positive" situation.

I spent hours debugging this so you don't have to. Don't thank me! 😄

The solution? Always use `getTransport()`:

```typescript
// ❌ This should work according to docs, but can be silent
Tone.Transport.start();

// ✅ This has proven to work reliably
const transport = Tone.getTransport();
transport.start();
```

## Dynamic Channel Scheduling

One of the powerful features of this system is the ability to schedule audio playback and channel routing in real-time. Here's how to implement dynamic scheduling:

```typescript
// We'll inject transport to make testing easier
interface PerformanceControllerConfig {
  audioManager: AudioManager;
  transport: Tone.Transport;
}

class PerformanceController {
  private audioManager: AudioManager;
  private transport: Tone.Transport;

  constructor(config: PerformanceControllerConfig) {
    this.audioManager = config.audioManager;
    this.transport = config.transport;
  }

  // Handle channel change from UI, keyboard, MIDI, etc.
  handleChannelChange(trackId: string, targetChannel: number) {
    // Get next safe time to make the switch (e.g., next 16th note)
    const quantizeTime = this.transport.nextSubdivision('16n');
    
    // Add a tiny offset to ensure smooth transition
    const switchTime = quantizeTime + 0.01;

    try {
      this.audioManager.rescheduleToChannel(trackId, targetChannel, switchTime);
      console.log(`Track ${trackId} scheduled to channel ${targetChannel} at ${switchTime}`);
    } catch (error) {
      console.error('Failed to switch channels:', error);
      // Handle the error in UI (show notification, etc.)
    }
  }

  // Preview channel routing (useful for headphone preview)
  previewChannel(trackId: string, previewChannel: number) {
    const now = this.transport.now();
    this.audioManager.rescheduleToChannel(trackId, previewChannel, now);
  }
}

// Example usage with dependency injection for better testing
const performanceController = new PerformanceController({
  audioManager: new AudioManager({ /* config */ }),
  transport: Tone.getTransport()
});

// In tests, you can mock the transport:
const mockTransport = {
  nextSubdivision: jest.fn().mockReturnValue(1),
  now: jest.fn().mockReturnValue(0)
};

const testController = new PerformanceController({
  audioManager: mockAudioManager,
  transport: mockTransport as unknown as Tone.Transport
});
```

This implementation allows you to:
1. Schedule precise playback timing using `Tone.js Transport`
2. Move audio between channels without interrupting playback
3. Synchronize multiple channel changes
4. Maintain timing relationships between different audio sources
5. Handle real-time interactions from various input sources (`UI`, `keyboard`, `MIDI`)
6. Preview channel routing before committing changes
7. Write reliable tests with `dependency injection`

The key here is that we're quantizing the channel switches to musical subdivisions (like `16th notes`) to keep everything in time with the music. We also add a tiny offset to ensure smooth transitions and handle any potential errors that might occur during the switch.

## Need Help?

Are you implementing multichannel audio in your web app? Running into issues? I'd love to help! Just head over to my contact page, and let's solve those audio routing challenges together. Whether it's a bug you can't squash or you need clarification on the concepts, I'm here to help! 🤝

Remember: Working with professional audio on the web is challenging, but with the right tools and understanding of the fundamentals, you can build something that works reliably. Keep experimenting! 🎹 